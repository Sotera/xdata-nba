import json
import os
import logging
import urllib
import urllib2
import re
from string import Template
from bs4 import BeautifulSoup

""" NOTES
This module takes the yahoo URLs generated from xdata.py and queries
the yahoo schedule page. From this page the code will match the anchor 
tag to the specific game. It will then extract the yahoo game url. It
will poll the game URL for posted comments

Also the comments currently contain a "view more" link for both
the individual comment chains and for the full list of comments for the 
game. The code currently does not account for pulling addition comments
by way of this link. That will take more substantial processing.

Additionally, the code currently assumes a reply depth of 1. Its possible
to reply to replies on the web page. This is not currently accounted for
within this code.
"""

""" Variables """
logging.basicConfig(filename='../../../yahoo.log', level=logging.DEBUG)
yahooConvTemplate = Template("http://sports.yahoo.com$gameUrl")
commentsTemplate = Template("http://sports.yahoo.com/_xhr/contentcomments/get_all/?content_id=$contentId&_device=full&done=http%3A%2F%2Fsports.yahoo.com$gameUrl&comments_listening_type=0&_media.modules.content_comments.switches._enable_view_others=1&_media.modules.content_comments.switches._enable_mutecommenter=1&enable_collapsed_comment=0")
outputDirPrefix = "../../../output/"
yahooUrlFile = "%syahoo_search_urls.txt" % outputDirPrefix
opener = urllib2.build_opener()
opener.addheaders = [('User-agent','Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]
contentIdPattern = re.compile("contentId: '(?P<cID>.*)',")

""" Pull comments and replies out of the HTML element """
def processFeedback(commentRoot, commentsFile):
    commenterName = commentRoot.find("span", {"class" : re.compile(r'\bprofile-link\b')}).text
    commenterComment = commentRoot.find("p", {"class" : re.compile(r'\bcomment-content\b')}).text.strip()
    commentsFile.write("%s::%s\n" % (commenterName, commenterComment))

if os.path.exists(yahooUrlFile):
    """ Read the URL file generated by the nba.com routine """
    with open(yahooUrlFile, "r") as urlFile:
        for line in urlFile:
            try:
                url, query, nbaGameId = line.split('|')
                nbaGameId = nbaGameId.rstrip('\n')
                logging.debug("Yahoo Search URL: %s\nQuery: %s\nGameId: %s" % (url, query, nbaGameId))
                unstructured = opener.open(url)
                soup = BeautifulSoup(unstructured)
                """ Follow the nba.com process file naming convention """
                commentsFileName = "%s00%s_yahoo_comments.txt" %(outputDirPrefix, nbaGameId)
                commentsFile = open(commentsFileName, 'w+')
                try:
                    """ Find the link that matches the game data """
                    for t in soup.find_all('tr', {"class" : "game link", "data-url" : re.compile(query)}):
                        gameUrl = yahooConvTemplate.substitute(gameUrl=t['data-url'])
                        logging.debug("Game URL:%s" % gameUrl)
                        print "Game URL:%s" % gameUrl
                        gameData = opener.open(gameUrl)
                        contentId = re.findall(contentIdPattern, gameData.read())[0]
                        logging.debug("ContentId: %s" % contentId)
                        print "ContentId: %s" % contentId
                        commentsURL = commentsTemplate.substitute(contentId=contentId,gameUrl=urllib.quote_plus(gameUrl))
                        logging.debug("Comments URL: %s" % commentsURL)
                        response = opener.open(commentsURL)
                        content = json.load(response, encoding='utf-8')
                        chatSoup = BeautifulSoup(content['commentList'])
                        for l in chatSoup(attrs={"class": "comment"}):
                            processFeedback(l, commentsFile)
                except Exception as e:
                    logging.error("Exception when processing comments:\n%s " % (e))
                finally:
                    commentsFile.close()
            except Exception as e:
                logging.error("Unable to open URL: %s \n%s " % (url, e))
                print "Unable to open URL: %s" % url
    urlFile.close()
opener.close()