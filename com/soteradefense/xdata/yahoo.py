import json
import os
import logging
import urllib
import urllib2
import re
from datetime import datetime
from string import Template
from bs4 import BeautifulSoup

""" NOTES
This module takes the yahoo URLs generated from xdata.py and queries
the yahoo schedule page. From this page the code will match the anchor 
tag to the specific game. It will then extract the yahoo game url. It
will poll the game URL for posted comments

Also the comments currently contain a "view more" link for both
the individual comment chains and for the full list of comments for the 
game. The code currently does not account for pulling addition comments
by way of this link. That will take more substantial processing.

Additionally, the code currently doesnt pull back replies to comments as
those are not in the initial pulldown. Additional code will be required
to gather that information.
"""

""" Variables """
logging.basicConfig(filename='../../../yahoo.log', level=logging.DEBUG)
yahooConvTemplate = Template("http://sports.yahoo.com$gameUrl")
commentsTemplate = Template("http://sports.yahoo.com/_xhr/contentcomments/get_all/?content_id=$contentId&_device=full&done=http%3A%2F%2Fsports.yahoo.com$gameUrl&comments_listening_type=0&_media.modules.content_comments.switches._enable_view_others=1&_media.modules.content_comments.switches._enable_mutecommenter=1&enable_collapsed_comment=0")
outputDirPrefix = "../../../output/"
yahooUrlFile = "%syahoo_search_urls.txt" % outputDirPrefix
opener = urllib2.build_opener()
opener.addheaders = [('User-agent','Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1')]
contentIdPattern = re.compile("contentId: '(?P<cID>.*)',")
startTime = datetime.now()
gamesProcessed = 0
commentsProcessed = 0
exceptionsThrown = 0

print 'Starting Retrieval'
logging.info('Staring Retrieval')

""" Pull comments and replies out of the HTML element """
def processFeedback(commentRoot, commentsFile):
    global commentsProcessed
    commenterName = commentRoot.find("span", {"class" : re.compile(r'\bprofile-link\b')}).text
    commenterComment = commentRoot.find("p", {"class" : re.compile(r'\bcomment-content\b')}).text.strip().replace('\n',' ')
    commentsFile.write("%s::%s\n" % (commenterName, commenterComment))
    commentsProcessed += 1

if os.path.exists(yahooUrlFile):
    """ Read the URL file generated by the nba.com routine """
    with open(yahooUrlFile, "r") as urlFile:
        for line in urlFile:
            try:
                url, query, nbaGameId = line.split('|')
                nbaGameId = nbaGameId.rstrip('\n')
                logging.debug("\n---Yahoo Search URL: %s\n---Query: %s\n---GameId: %s" % (url, query, nbaGameId))
                unstructured = opener.open(url)
                soup = BeautifulSoup(unstructured)
                """ Follow the nba.com process file naming convention """
                commentsFileName = "%s00%s_yahoo_comments.txt" %(outputDirPrefix, nbaGameId)
                commentsFile = open(commentsFileName, 'w+')
                try:
                    """ Find the link that matches the game data """
                    for t in soup.find_all('tr', {"class" : "game link", "data-url" : re.compile(query)}):
                        gameUrl = yahooConvTemplate.substitute(gameUrl=t['data-url'])
                        logging.debug("Game URL:%s" % gameUrl)
                        gameData = opener.open(gameUrl)
                        contentId = re.findall(contentIdPattern, gameData.read())[0]
                        logging.debug("ContentId: %s" % contentId)
                        commentsURL = commentsTemplate.substitute(contentId=contentId,gameUrl=urllib.quote_plus(gameUrl))
                        logging.debug("Comments URL: %s" % commentsURL)
                        response = opener.open(commentsURL)
                        content = json.load(response, encoding='utf-8')
                        chatSoup = BeautifulSoup(content['commentList'])
                        for l in chatSoup(attrs={"class": "comment"}):
                            try:
                                processFeedback(l, commentsFile)
                            except Exception as e:
                                logging.exception("Exception when processing comments")
                                exceptionsThrown += 1
                                """ Continue with remaining URLs """
                                continue
                except Exception as e:
                    logging.exception("Exception retrieving comments")
                    exceptionsThrown += 1
                    continue
                finally:
                    commentsFile.close()
                gamesProcessed += 1
                print("."),
            except Exception as e:
                logging.exception("Unable to open URL: %s" % url)
                print("!"),
                exceptionsThrown += 1
                """ Continue with remaining URLs """
                continue
    urlFile.close()
opener.close()

endTime = datetime.now()
delta = endTime - startTime

print '\nStopping Retrieval\n-- Processing Time: %d seconds\n-- Games Processed: %s\n-- Comments Processed: %s\n-- Exceptions Caught: %s' %(delta.seconds + delta.microseconds/1E6, gamesProcessed, commentsProcessed, exceptionsThrown)
logging.info('Stopping Retrieval\n-- Processing Time: %d seconds\n-- Games Processed: %s\n-- Comments Processed: %s\n-- Exceptions Caught: %s' %(delta.seconds + delta.microseconds/1E6, gamesProcessed, commentsProcessed, exceptionsThrown))